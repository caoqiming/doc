# Deep Guided Filter (DGF)

Deep Guided Filter (DGF) 是一种结合了传统经典算法 引导滤波 (Guided Filter) 与 深度学习 的神经网络模块。
Deep Guided Filter 的思路：用 CNN 在低分辨率下预测特征，然后用引导滤波的数学原理，将这些特征“平滑地”放大回高分辨率。

## 工作原理

DGF 通常分为两个分支同步运行：

1. 低分辨率分支 (Low-res Branch)：
   将原始高分辨率图下采样。
   通过一个轻量级的 CNN（如卷积层）提取关键特征或进行初步处理。

2. 引导滤波模块 (Guided Filter Layer)：
   **引导图 (Guidance Image)：通常是原始的高分辨率原图。**
   **输入图 (Input Image)：低分辨率分支得到的处理结果。**
   操作：利用引导图的边缘信息，通过线性变换将低分辨率结果上采样，从而生成既有深度学习效果、又保留了原图清晰边缘的高分辨率输出。

## Guided Filter

> 引导滤波（Guided Filter）是由何凯明（Kaiming He）博士在 2010 年提出的一种线性时间复杂度的局部平滑滤波器。

首先，为什么叫引导滤波，因为它其实是输入了两张图：一张引导图像 I、一张要被处理的输入图像 p
引导滤波的核心假设是：在一个局部的窗口 $\omega_k$（以像素 $k$ 为中心）内，输出图像 $q$ 与引导图像 $I$ 之间存在线性关系。

$$
q_i = a_k I_i + b_k, \quad \forall i \in \omega_k
$$

- $I_i$：引导图像在像素 $i$ 的值。
- $q_i$：输出图像（滤波后的结果）在像素 $i$ 的值。
- $a_k, b_k$：窗口 $\omega_k$ 内的线性系数，在局部窗口内被视为常数。

我们需要让输出图像 $q$ 尽可能接近输入图像 $p$
也就是我们最小化以下代价函数

$$
E(a_k, b_k) = \sum_{i \in \omega_k} \left( (a_k I_i + b_k - p_i)^2 + \epsilon a_k^2 \right)
$$

- $p_i$：待滤波的原始输入图像。
- $\epsilon$：一个微小的正则化参数，防止 $a_k$ 过大，同时也决定了滤波的“平滑程度”。

通过对 $a_k$ 和 $b_k$ 求导并令其为零，可以得到这两个系数的闭式解：

$$
a_k = \frac{\frac{1}{|\omega|} \sum_{i \in \omega_k} I_i p_i - \mu_k \bar{p}_k}{\sigma_k^2 + \epsilon}
$$

- $\mu_k$ 是 $I$ 在窗口内的均值。
- $\sigma_k^2$ 是 $I$ 在窗口内的方差。
- $\bar{p}_k$ 是 $p$ 在窗口内的均值。

$$
b_k = \bar{p}_k - a_k \mu_k
$$

由于一个像素 $i$ 会被包含在多个窗口 $\omega_k$ 中，每个窗口算出的 $a_k, b_k$ 不同，因此对所有包含像素 $i$ 的窗口所得的系数取平均：

$$
q_i = \bar{a}_i I_i + \bar{b}_i
$$

### 详细逻辑

我们可以重点观察 $a_k$ 的计算公式，它决定了权重的分配：

- 高方差区域（边缘区域）：如果窗口内包含明显的边缘，$\sigma_k^2$ 会很大（远大于 $\epsilon$）。此时 $a_k \approx 1$，$b_k \approx 0$。这意味着输出 $q \approx I$。也就是说，在边缘处，滤波器会严格遵循引导图的纹理，从而保留边缘。
- 低方差区域（平滑区域）：如果窗口内基本是平坦的，$\sigma_k^2 \approx 0$。此时 $a_k \approx 0$，$b_k \approx \bar{p}_k$。这意味着输出 $q \approx \bar{p}_k$。也就是说，在平坦处，它执行的是均值滤波，从而消除噪声。

## DGF 原理

在 Deep Guided Filter (DGF) 中，神经网络不再像传统算法那样根据固定公式死板地计算 $a_k$ 和 $b_k$，而是通过端到端（End-to-End）的学习来预测这些系数。它的精妙之处在于将引导滤波的数学形式封装成了一个可微的神经网络层。
DGF 将整个过程拆解为两个部分：

- 系数预测网络 (Coefficient Prediction Network)：通常是一个轻量级的 CNN（如几层卷积层）。它的输入是低分辨率图，输出不是最终图像，而是两张“系数图”：$A$ 图（存储所有的 $a_k$）和 $B$ 图（存储所有的 $b_k$）。
- 线性变换层 (Linear Transformation Layer)：这是一个标准的算术层，没有参数。它接收 CNN 预测出的 $a$、$b$ 以及高分辨率引导图 $I$，按照公式 $q = a \cdot I + b$ 直接算出结果。

### 自动学习的具体过程

1. 低尺度下的“思考”：CNN 在低分辨率下观察图像的语义（比如哪里是头发丝，哪里是背景）。它会输出局部窗口内的最佳线性拟合参数。
2. 上采样回归：预测出来的 $a$ 和 $b$ 也是低分辨率的，网络会通过双线性插值将 $a$ 和 $b$ 放大到与原始高分辨率引导图 $I$ 相同的大小。
3. 反向传播 (Backpropagation)：训练时，我们会有一个高清的真值图（Ground Truth）。如果输出的 $q$ 与真值不符，误差会通过公式 $q = a \cdot I + b$ 反向传回给 CNN。因为 $I$ 是常数（输入数据），所以梯度可以直接流向 $a$ 和 $b$。CNN 就会根据梯度调整自己的卷积核权重，学习在什么样的像素特征下该给出什么样的 $a$ 和 $b$。
